{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOk4CC0++H6DWAwjWaKtFsH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreent/large-language-model/blob/main/2%20Embeddings%20and%20Vector%20Search%20-%20Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings and Vector Search\n",
        "\n",
        "In this lab, we will apply the text vectorization, search, and question answering workflow that you learned in the demo. The dataset we will use this time will be on talk titles and sessions from [Data + AI Summit 2023](https://www.databricks.com/dataaisummit/).\n",
        "\n",
        "##Learning Objectives\n",
        "1. Learn how to use Chroma to store your embedding vectors and conduct similarity search\n",
        "2. Use OpenAI GPT-3.5 to generate response to your prompt"
      ],
      "metadata": {
        "id": "e1_YPyfUW58q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Libraries:\n",
        "* [transformers](https://github.com/huggingface/transformers) is for Hugging Face's transformer models\n",
        "* [datasets](https://github.com/huggingface/datasets) is for Hugging Face's datasets\n",
        "* [chromadb](https://github.com/chroma-core/chroma) is for ChromaDB vector database"
      ],
      "metadata": {
        "id": "Ed1F95YWW6nM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install git+https://github.com/huggingface/transformers\n",
        "!pip -q install git+https://github.com/huggingface/datasets\n",
        "!pip -q install chromadb==0.3.21 tiktoken==0.3.3"
      ],
      "metadata": {
        "id": "NV_a2RPSYXJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28355d9e-12f3-49fc-9d73-65028001b603"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for datasets (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m597.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m966.2/966.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Reading dataCommon LLM applications\n",
        "\n",
        "In this section, we are going to use the data on <a href=\"https://newscatcherapi.com/\" target=\"_blank\">news topics collected by the NewsCatcher team</a>, who collect and index news articles and release them to the open-source community. The dataset can be downloaded from <a href=\"https://www.kaggle.com/kotartemiy/topic-labeled-news-dataset\" target=\"_blank\">Kaggle</a>.\n"
      ],
      "metadata": {
        "id": "ztneW42xZOiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# URL for our data science talk dataset, dais23_talks.csv\n",
        "URL = \"https://drive.google.com/file/d/1hHDrzTyV3YJM-cR5ABHKvGIP8wVINNPd/view?usp=sharing\"\n",
        "FILE_PATH = \"https://drive.google.com/uc?export=download&id=\" + URL.split(\"/\")[-2]\n",
        "\n",
        "pdf = pd.read_csv(FILE_PATH, sep=\",\")\n",
        "pdf[\"id\"] = pdf.index\n",
        "display(pdf)"
      ],
      "metadata": {
        "id": "nbMlFyXXZTS8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "f23ed659-ed34-4942-aaa1-44afeb533a09"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                 Title  \\\n",
              "0    Nebula: The Journey of Scaling Instacart’s Dat...   \n",
              "1    Satellite Imaginary Data Processing Using Apac...   \n",
              "2     From Snowflake to Enterprise-Scale Apache Spark™   \n",
              "3    The Future of Data Orchestration: Asset-Based ...   \n",
              "4    Photon for Dummies: How Does this New Executio...   \n",
              "..                                                 ...   \n",
              "176                                       Ray on Spark   \n",
              "177  Why Delta Lake is the best storage format for ...   \n",
              "178    Fine tuning & scaling Hugging Face with Ray AIR   \n",
              "179  Breaking Barriers with Databricks Lakehouse - ...   \n",
              "180  Scaling Deep Learning using Delta Lake storage...   \n",
              "\n",
              "                                              Abstract  \\\n",
              "0    Instacart has gone through immense growth duri...   \n",
              "1    Agriculture is a complex ecosystem. Understand...   \n",
              "2    Akamai mPulse is a real user monitoring (RUM) ...   \n",
              "3    Data orchestration is a core component for any...   \n",
              "4    Did you finish the Photon whitepaper and think...   \n",
              "..                                                 ...   \n",
              "176  Ray and its associated native libraries make s...   \n",
              "177  pandas analyses are often limited by file form...   \n",
              "178  Hugging Face Transformers is a popular open-so...   \n",
              "179  Cybersecurity incidents are costly, and using ...   \n",
              "180  Delta Lake is an open-source storage format th...   \n",
              "\n",
              "                                             full_text   id  \n",
              "0    Title: Nebula: The Journey of Scaling Instacar...    0  \n",
              "1    Title: Satellite Imaginary Data Processing Usi...    1  \n",
              "2    Title: From Snowflake to Enterprise-Scale Apac...    2  \n",
              "3    Title: The Future of Data Orchestration: Asset...    3  \n",
              "4    Title: Photon for Dummies: How Does this New E...    4  \n",
              "..                                                 ...  ...  \n",
              "176  Title: Ray on Spark\\n                Abstract:...  176  \n",
              "177  Title: Why Delta Lake is the best storage form...  177  \n",
              "178  Title: Fine tuning & scaling Hugging Face with...  178  \n",
              "179  Title: Breaking Barriers with Databricks Lakeh...  179  \n",
              "180  Title: Scaling Deep Learning using Delta Lake ...  180  \n",
              "\n",
              "[181 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-0c161a5c-1839-474a-948e-00456fbe1862\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Abstract</th>\n",
              "      <th>full_text</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nebula: The Journey of Scaling Instacart’s Dat...</td>\n",
              "      <td>Instacart has gone through immense growth duri...</td>\n",
              "      <td>Title: Nebula: The Journey of Scaling Instacar...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Satellite Imaginary Data Processing Using Apac...</td>\n",
              "      <td>Agriculture is a complex ecosystem. Understand...</td>\n",
              "      <td>Title: Satellite Imaginary Data Processing Usi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From Snowflake to Enterprise-Scale Apache Spark™</td>\n",
              "      <td>Akamai mPulse is a real user monitoring (RUM) ...</td>\n",
              "      <td>Title: From Snowflake to Enterprise-Scale Apac...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Future of Data Orchestration: Asset-Based ...</td>\n",
              "      <td>Data orchestration is a core component for any...</td>\n",
              "      <td>Title: The Future of Data Orchestration: Asset...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Photon for Dummies: How Does this New Executio...</td>\n",
              "      <td>Did you finish the Photon whitepaper and think...</td>\n",
              "      <td>Title: Photon for Dummies: How Does this New E...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>Ray on Spark</td>\n",
              "      <td>Ray and its associated native libraries make s...</td>\n",
              "      <td>Title: Ray on Spark\\n                Abstract:...</td>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>Why Delta Lake is the best storage format for ...</td>\n",
              "      <td>pandas analyses are often limited by file form...</td>\n",
              "      <td>Title: Why Delta Lake is the best storage form...</td>\n",
              "      <td>177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>Fine tuning &amp; scaling Hugging Face with Ray AIR</td>\n",
              "      <td>Hugging Face Transformers is a popular open-so...</td>\n",
              "      <td>Title: Fine tuning &amp; scaling Hugging Face with...</td>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>Breaking Barriers with Databricks Lakehouse - ...</td>\n",
              "      <td>Cybersecurity incidents are costly, and using ...</td>\n",
              "      <td>Title: Breaking Barriers with Databricks Lakeh...</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>Scaling Deep Learning using Delta Lake storage...</td>\n",
              "      <td>Delta Lake is an open-source storage format th...</td>\n",
              "      <td>Title: Scaling Deep Learning using Delta Lake ...</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>181 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c161a5c-1839-474a-948e-00456fbe1862')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-c5d9afee-1029-4550-a8d6-37fce88c8c1b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c5d9afee-1029-4550-a8d6-37fce88c8c1b')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-c5d9afee-1029-4550-a8d6-37fce88c8c1b button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c161a5c-1839-474a-948e-00456fbe1862 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c161a5c-1839-474a-948e-00456fbe1862');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Library: FAISS\n",
        "Vector libraries are often sufficient for small, static data. Since it's not a full-fledged database solution, it doesn't have the CRUD (Create, Read, Update, Delete) support. Once the index has been built, if there are more vectors that need to be added/removed/edited, the index has to be rebuilt from scratch.\n",
        "\n",
        "That said, vector libraries are easy, lightweight, and fast to use. Examples of vector libraries are [FAISS](https://faiss.ai/), [ScaNN](https://github.com/google-research/google-research/tree/master/scann), [ANNOY](https://github.com/spotify/annoy), and [HNSM](https://arxiv.org/abs/1603.09320).\n",
        "\n",
        "FAISS has several ways for similarity search: L2 (Euclidean distance), cosine similarity. You can read more about their implementation on their [GitHub](https://github.com/facebookresearch/faiss/wiki/Getting-started#searching) page or [blog post](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/). They also published their own [best practice guide here](https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index).\n",
        "\n",
        "If you'd like to read up more on the comparisons between vector libraries and databases, [here is a good blog post](https://weaviate.io/blog/vector-library-vs-vector-database#feature-comparison---library-versus-database).\n"
      ],
      "metadata": {
        "id": "iYQ7YcfTZAJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The overall workflow of FAISS is captured in the diagram below.\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/0*ouf0eyQskPeGWIGm\" width=700>\n",
        "\n",
        "Source: [How to use FAISS to build your first similarity search by Asna Shafiq](https://medium.com/loopio-tech/how-to-use-faiss-to-build-your-first-similarity-search-bf0f708aa772).\n",
        "\n"
      ],
      "metadata": {
        "id": "z3fef8tTgMVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import InputExample\n",
        "\n",
        "pdf_subset = pdf.head(1000)\n",
        "\n",
        "def example_create_fn(doc1: pd.Series) -> InputExample:\n",
        "    \"\"\"\n",
        "    Helper function that outputs a sentence_transformer guid, label, and text\n",
        "    \"\"\"\n",
        "    return InputExample(texts=[doc1])\n",
        "\n",
        "faiss_train_examples = pdf_subset.apply(\n",
        "    lambda x: example_create_fn(x[\"title\"]), axis=1\n",
        ").tolist()"
      ],
      "metadata": {
        "id": "dvoOLRZQY4hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Vectorize text into embedding vectors\n",
        "We will be using `Sentence-Transformers` [library](https://www.sbert.net/) to load a language model to vectorize our text into embeddings. The library hosts some of the most popular transformers on [Hugging Face Model Hub](https://huggingface.co/sentence-transformers).\n",
        "Here, we are using the `model = SentenceTransformer(\"all-MiniLM-L6-v2\")` to generate embeddings.\n"
      ],
      "metadata": {
        "id": "RBFbSINwbXvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\n",
        "    \"all-MiniLM-L6-v2\",\n",
        ")  # Use a pre-cached model\n",
        "faiss_title_embedding = model.encode(pdf_subset.title.values.tolist())\n",
        "len(faiss_title_embedding), len(faiss_title_embedding[0])"
      ],
      "metadata": {
        "id": "Y8jWhQQubgTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Saving embedding vectors to FAISS index\n",
        "Below, we create the FAISS index object based on our embedding vectors, normalize vectors, and add these vectors to the FAISS index.\n"
      ],
      "metadata": {
        "id": "kHpQuZN3ahWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "pdf_to_index = pdf_subset.set_index([\"id\"], drop=False)\n",
        "id_index = np.array(pdf_to_index.id.values).flatten().astype(\"int\")\n",
        "\n",
        "content_encoded_normalized = faiss_title_embedding.copy()\n",
        "faiss.normalize_L2(content_encoded_normalized)\n",
        "\n",
        "# Index1DMap translates search results to IDs: https://faiss.ai/cpp_api/file/IndexIDMap_8h.html#_CPPv4I0EN5faiss18IndexIDMapTemplateE\n",
        "# The IndexFlatIP below builds index\n",
        "index_content = faiss.IndexIDMap(faiss.IndexFlatIP(len(faiss_title_embedding[0])))\n",
        "index_content.add_with_ids(content_encoded_normalized, id_index)"
      ],
      "metadata": {
        "id": "F3VtfFRqZJJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Search for relevant documents\n",
        "\n",
        "We define a search function below to first vectorize our query text, and then search for the vectors with the closest distance.\n"
      ],
      "metadata": {
        "id": "vAT8lqq6g2nI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_content(query, pdf_to_index, k=3):\n",
        "    query_vector = model.encode([query])\n",
        "    faiss.normalize_L2(query_vector)\n",
        "\n",
        "    # We set k to limit the number of vectors we want to return\n",
        "    top_k = index_content.search(query_vector, k)\n",
        "    ids = top_k[1][0].tolist()\n",
        "    similarities = top_k[0][0].tolist()\n",
        "    results = pdf_to_index.loc[ids]\n",
        "    results[\"similarities\"] = similarities\n",
        "    return results"
      ],
      "metadata": {
        "id": "udH8Mdpwa3MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can query for similar content! Notice that you did not have to configure any database networks beforehand nor pass in any credentials. FAISS works locally with your code.\n"
      ],
      "metadata": {
        "id": "hMBk56xbhBTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(search_content(\"animal\", pdf_to_index))"
      ],
      "metadata": {
        "id": "19D8MTQFa7KX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Up until now, we haven't done the last step of conducting Q/A with a language model yet. We are going to demonstrate this with Chroma, a vector database.\n"
      ],
      "metadata": {
        "id": "vLDe5l3ZhOfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Database: Chroma\n",
        "\n",
        "Chroma is an open-source embedding database. The company just raised its [seed funding in April 2023](https://www.trychroma.com/blog/seed) and is quickly becoming popular to support LLM-based applications.\n"
      ],
      "metadata": {
        "id": "RDspun6ShUyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a folder required by ChromaDB for persisting its data\n",
        "!mkdir -p /content/user_db"
      ],
      "metadata": {
        "id": "f7bQGgFx1KKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "\n",
        "chroma_client = chromadb.Client(\n",
        "    Settings(\n",
        "        chroma_db_impl=\"duckdb+parquet\",\n",
        "        persist_directory=\"/content/user_db\",  # this is an optional argument. If you don't supply this, the data will be ephemeral\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "HOvWICgFhHw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chroma Concept: Collection\n",
        "\n",
        "Chroma `collection` is akin to an index that stores one set of your documents.\n",
        "\n",
        "According to the [docs](https://docs.trychroma.com/getting-started):\n",
        "> Collections are where you will store your embeddings, documents, and additional metadata\n",
        "\n",
        "The nice thing about ChromaDB is that if you don't supply a model to vectorize text into embeddings, it will automatically load a default embedding function, i.e. `SentenceTransformerEmbeddingFunction`. It can handle tokenization, embedding, and indexing automatically for you. If you would like to change the embedding model, read [here on how to do that](https://docs.trychroma.com/embeddings). TLDR: you can add an optional `model_name` argument.\n",
        "\n",
        "You can read [the documentation here](https://docs.trychroma.com/usage-guide#using-collections) on rules for collection names.\n"
      ],
      "metadata": {
        "id": "LrncK50zhi0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection_name = \"my_news\"\n",
        "\n",
        "# If you have created the collection before, you need to delete the collection first\n",
        "if len(chroma_client.list_collections()) > 0 and collection_name in [chroma_client.list_collections()[0].name]:\n",
        "    chroma_client.delete_collection(name=collection_name)\n",
        "\n",
        "print(f\"Creating collection: '{collection_name}'\")\n",
        "collection = chroma_client.create_collection(name=collection_name)"
      ],
      "metadata": {
        "id": "i7OCpJetbCES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Add data to collection\n",
        "\n",
        "Since we are re-using the same data, we can skip the step of reading data. As mentioned in the text above, Chroma can take care of text vectorization for us, so we can directly add text to the collection and Chroma will convert the text into embeddings behind the scene.\n"
      ],
      "metadata": {
        "id": "JCkWYupPbxdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(pdf_subset)"
      ],
      "metadata": {
        "id": "NM79AfPlb8rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each document must have a unique `id` associated with it and it is up to you to check that there are no duplicate ids.\n",
        "\n",
        "Adding data to collection will take some time to run, especially when there is a lot of data. In the cell below, we intentionally write only a subset of data to the collection to speed things up.\n"
      ],
      "metadata": {
        "id": "czmB-tedcInH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection.add(\n",
        "    documents=pdf_subset[\"title\"][:100].tolist(),\n",
        "    metadatas=[{\"topic\": topic} for topic in pdf_subset[\"topic\"][:100].tolist()],\n",
        "    ids=[f\"id{x}\" for x in range(100)],\n",
        ")"
      ],
      "metadata": {
        "id": "foA_7EmicFr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Query for 10 relevant documents on \"space\"\n",
        "\n",
        "We will return 10 most relevant documents. You can think of `10` as 10 nearest neighbors. You can also change the number of results returned as well.\n"
      ],
      "metadata": {
        "id": "4AzQpNqPmClG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "results = collection.query(query_texts=[\"space\"], n_results=10)\n",
        "\n",
        "print(json.dumps(results, indent=4))"
      ],
      "metadata": {
        "id": "jXFcMDCBcTxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bonus: Add filter statement\n",
        "\n",
        "In addition to conducting relevancy search, we can also add filter statements. Refer to the [documentation](https://docs.trychroma.com/usage-guide#using-where-filters) for more information.\n"
      ],
      "metadata": {
        "id": "gubVK_QGmJlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection.query(query_texts=[\"space\"], where={\"topic\": \"SCIENCE\"}, n_results=10)"
      ],
      "metadata": {
        "id": "_wxnFAvBcZoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bonus: Update data in a collection\n",
        "\n",
        "Unlike a vector library, vector databases support changes to the data so we can update or delete data.\n",
        "\n",
        "Indeed, we can update or delete data in a Chroma collection.\n"
      ],
      "metadata": {
        "id": "YpYg7jdBciEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection.delete(ids=[\"id0\"])"
      ],
      "metadata": {
        "id": "3W23EJ5hm-TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The record with `ids=0` is no longer present."
      ],
      "metadata": {
        "id": "oamMId_Ec4be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection.get(\n",
        "    ids=[\"id0\"],\n",
        ")"
      ],
      "metadata": {
        "id": "4rn1EyaicdAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also update a specific data point."
      ],
      "metadata": {
        "id": "W7yBnSh2nEye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection.get(\n",
        "    ids=[\"id2\"],\n",
        ")"
      ],
      "metadata": {
        "id": "5sy5z7oAc_1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collection.update(\n",
        "    ids=[\"id2\"],\n",
        "    metadatas=[{\"topic\": \"TECHNOLOGY\"}],\n",
        ")"
      ],
      "metadata": {
        "id": "NnK8lcTLnJaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt engineering for question answering\n",
        "\n",
        "Now that we have identified documents about space from the news dataset, we can pass these documents as additional context for a language model to generate a response based on them!\n",
        "\n",
        "We first need to pick a `text-generation` model. Below, we use a Hugging Face model. You can also use OpenAI as well, but you will need to get an Open AI token and [pay based on the number of tokens](https://openai.com/pricing)."
      ],
      "metadata": {
        "id": "4FTDeQ8ZdDXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "model_id = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "lm_model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=lm_model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "id": "ARpkmgQedCPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's where prompt engineering, which is developing prompts, comes in. We pass in the context in our `prompt_template` but there are numerous ways to write a prompt. Some prompts may generate better results than the others and it requires some experimentation to figure out how best to talk to the model. Each language model behaves differently to prompts.\n",
        "\n",
        "Our prompt template below is inspired from a [2023 paper on program-aided language model](https://arxiv.org/pdf/2211.10435.pdf). The authors have provided their sample prompt template [here](https://github.com/reasoning-machines/pal/blob/main/pal/prompt/date_understanding_prompt.py).\n",
        "\n",
        "The following links also provide some helpful guidance on prompt engineering:\n",
        "- [Prompt engineering with OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)\n",
        "- [GitHub repo that compiles best practices to interact with ChatGPT](https://github.com/f/awesome-chatgpt-prompts)\n"
      ],
      "metadata": {
        "id": "3QwGs2vXnYMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What's the latest news on space development?\"\n",
        "context = \" \".join([f\"#{str(i)}\" for i in results[\"documents\"][0]])\n",
        "prompt_template = f\"Relevant context: {context}\\n\\n The user's question: {question}\""
      ],
      "metadata": {
        "id": "gjQvdy75fUQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm_response = pipe(prompt_template)\n",
        "print(lm_response[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "tnEPaYVyfWhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have just completed the implementation of your first text vectorization, search, and question answering workflow (that requires prompt engineering)!\n",
        "\n",
        "In the lab, you will apply your newly gained knowledge to a different dataset. You can also check out the optional modules on Pinecone and Weaviate to learn how to set up vector databases that offer enterprise offerings.\n"
      ],
      "metadata": {
        "id": "lijDPp1Mfbin"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gSDrBOrC1z2q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}